{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7a37b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datasets\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import allennlp.modules.conditional_random_field as crf\n",
    "###\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from data import Conll2003, UNK, PAD\n",
    "from util import pad_batch, pad_test_batch, count_parameters, calculate_epoch_time, build_mappings\n",
    "from model import BiLSTM_CRF\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fb6a615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    conll_dataset = datasets.load_dataset('conll2003')\n",
    "    train_dataset = conll_dataset['train']\n",
    "    valid_dataset = conll_dataset['validation']\n",
    "    test_dataset = conll_dataset['test']\n",
    "    return train_dataset, valid_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "290d4715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device() -> torch.device:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abbd3f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, optimizer, clip:int) -> float:\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    with tqdm(dataloader, unit='batch') as tqdm_loader:\n",
    "        for x_padded, x_lens, y_padded in tqdm_loader:\n",
    "            optimizer.zero_grad()\n",
    "            result = model(x_padded, x_lens, y_padded, decode=False)\n",
    "            neg_log_likelihood = result['loss']\n",
    "            neg_log_likelihood.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            optimizer.step()\n",
    "            epoch_loss += neg_log_likelihood.item()\n",
    "    return epoch_loss/len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a891ca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader) -> float:\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        with tqdm(dataloader, unit='batch') as tqdm_loader:\n",
    "            for x_padded, x_lens, y_padded in tqdm_loader:\n",
    "                result = model(x_padded, x_lens, y_padded, decode=False)\n",
    "                neg_log_likelihood = result['loss']\n",
    "                epoch_loss += neg_log_likelihood.item()\n",
    "    return epoch_loss/len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4b5ee67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_eval(test_data, model, batch_size, idx_to_tokens, tokens_to_idx):\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        for batch_idx in range(len(test_data) // batch_size):\n",
    "            batch = test_data.select(range(\n",
    "                batch_size * batch_idx,\n",
    "                batch_size * (batch_idx + 1)\n",
    "            ))\n",
    "            gold_labels = batch['ner_tags']\n",
    "            tokens = batch['tokens']\n",
    "            encoded_tokens = []\n",
    "            for token_seq in tokens:\n",
    "                encoded_seq = []\n",
    "                for token in token_seq:\n",
    "                    if token in tags_to_idx:\n",
    "                        encoded_seq.append(tags_to_idx[token])\n",
    "                    else:\n",
    "                        encoded_seq.append(tags_to_idx[UNK])\n",
    "                encoded_tokens.append(torch.LongTensor(encoded_seq))\n",
    "            print(\"encoded tokens: \", encoded_tokens)\n",
    "            batch_predictions = decode_batch(model, encoded_tokens, idx_to_tokens=idx_to_tokens)\n",
    "            print(\"comp: \", gold_labels, batch_predictions)\n",
    "            break\n",
    "    # change when doing actual calcs\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6af3e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch decoding - hasn't been tested\n",
    "def decode_batch(model, batch, idx_to_tags:Dict[int, str]):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        padded_batch = pad_test_batch(batch)\n",
    "        x_padded, x_lens = padded_batch\n",
    "        result = model(x_padded, x_lens, None, decode=True)\n",
    "        # need to fix def bug here\n",
    "        predicted_tags = result['tags'][0][0]\n",
    "        actual_pred_tags = []\n",
    "        for pred in predicted_tags:\n",
    "            actual_pred_tags.append([idx_to_tags[i] for i in pred])\n",
    "    return actual_pred_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19fa8ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset conll2003 (/Users/sabhyachhabria/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/40e7cb6bcc374f7c349c83acd1e9352a4f09474eb691f64f364ee62eb65d0ca6)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e83cc94e94e6433197ff887c866a8500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train, val, test = load_data()\n",
    "ner_tags = train.features['ner_tags'].feature.names\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a131655",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_to_idx, idx_to_tokens = build_mappings(train['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e4a8e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Conll2003(\n",
    "        examples=train['tokens'][:100], labels=train['ner_tags'][:100],\n",
    "        ner_tags=ner_tags, idx_to_tokens=idx_to_tokens, tokens_to_idx=tokens_to_idx,\n",
    "        device=device\n",
    "    )\n",
    "val_data = Conll2003(\n",
    "        examples=val['tokens'][:100], labels=val['ner_tags'][:100],\n",
    "        ner_tags=ner_tags, idx_to_tokens=idx_to_tokens, tokens_to_idx=tokens_to_idx,\n",
    "        device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df474d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=train_data, batch_size=16, shuffle=True, collate_fn=pad_batch)\n",
    "val_dataloader = DataLoader(dataset=val_data, batch_size=16, shuffle=True, collate_fn=pad_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e02375d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "crf_constraints = crf.allowed_transitions(\n",
    "        constraint_type='BIO',\n",
    "        labels=train_data.idx_to_tags\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70094409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTM_CRF(\n",
       "  (embeddings): Embedding(23624, 50)\n",
       "  (lstm): LSTM(50, 128, batch_first=True, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (linear): Linear(in_features=256, out_features=9, bias=True)\n",
       "  (crf): ConditionalRandomField()\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bilstm_crf = BiLSTM_CRF(\n",
    "        device=device,\n",
    "        vocab_size=len(idx_to_tokens.keys()),\n",
    "        num_tags=len(train_data.idx_to_tags.keys()),\n",
    "        embedding_dim=50,\n",
    "        lstm_hidden_dim=256,\n",
    "        lstm_num_layers=1,\n",
    "        dropout=0.2,\n",
    "        constraints=crf_constraints,\n",
    "        pad_idx=train_data.tokens_to_idx[PAD]\n",
    "    )\n",
    "bilstm_crf.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4991e8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,367,932 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "num_params = count_parameters(bilstm_crf)\n",
    "print(f'The model has {num_params:,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9a33bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(bilstm_crf.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f478108c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00,  8.98batch/s]\n"
     ]
    }
   ],
   "source": [
    "train_loss = train_model(\n",
    "    model=bilstm_crf, dataloader=train_dataloader, optimizer=optimizer, clip=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78be609c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 74.80batch/s]\n"
     ]
    }
   ],
   "source": [
    "val_loss = evaluate_model(model=bilstm_crf, dataloader=val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "88d6bed2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tags_to_idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0p/9983bz9s4bzd5n_hzcj8qwtc0000gn/T/ipykernel_60902/1687202025.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m test_f1 = test_eval(test_data=test, model=bilstm_crf, batch_size=100,\n\u001b[0m\u001b[1;32m      2\u001b[0m                             idx_to_tokens=idx_to_tokens, tokens_to_idx=tokens_to_idx)\n",
      "\u001b[0;32m/var/folders/0p/9983bz9s4bzd5n_hzcj8qwtc0000gn/T/ipykernel_60902/1798020555.py\u001b[0m in \u001b[0;36mtest_eval\u001b[0;34m(test_data, model, batch_size, idx_to_tokens, tokens_to_idx)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mencoded_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoken_seq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtags_to_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                         \u001b[0mencoded_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags_to_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tags_to_idx' is not defined"
     ]
    }
   ],
   "source": [
    "test_f1 = test_eval(test_data=test, model=bilstm_crf, batch_size=100,\n",
    "                            idx_to_tokens=idx_to_tokens, tokens_to_idx=tokens_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361bf2fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
