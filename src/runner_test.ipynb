{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bb626dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datasets\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import allennlp.modules.conditional_random_field as crf\n",
    "###\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from data import Conll2003, UNK, PAD\n",
    "from util import pad_batch, pad_test_batch, count_parameters, calculate_epoch_time, build_mappings\n",
    "from model import BiLSTM_CRF\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "694679c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    conll_dataset = datasets.load_dataset('conll2003')\n",
    "    train_dataset = conll_dataset['train']\n",
    "    valid_dataset = conll_dataset['validation']\n",
    "    test_dataset = conll_dataset['test']\n",
    "    return train_dataset, valid_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b50aca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device() -> torch.device:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bc4d59e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, optimizer, clip:int) -> float:\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    with tqdm(dataloader, unit='batch') as tqdm_loader:\n",
    "        for x_padded, x_lens, y_padded in tqdm_loader:\n",
    "            optimizer.zero_grad()\n",
    "            result = model(x_padded, x_lens, y_padded, decode=False)\n",
    "            neg_log_likelihood = result['loss']\n",
    "            neg_log_likelihood.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            optimizer.step()\n",
    "            epoch_loss += neg_log_likelihood.item()\n",
    "    return epoch_loss/len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "208bc7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader) -> float:\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        with tqdm(dataloader, unit='batch') as tqdm_loader:\n",
    "            for x_padded, x_lens, y_padded in tqdm_loader:\n",
    "                result = model(x_padded, x_lens, y_padded, decode=False)\n",
    "                neg_log_likelihood = result['loss']\n",
    "                epoch_loss += neg_log_likelihood.item()\n",
    "    return epoch_loss/len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1635bcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_eval(test_data, model, batch_size, idx_to_tokens, tokens_to_idx, idx_to_tags):\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        for batch_idx in range(len(test_data) // batch_size):\n",
    "            batch = test_data.select(range(\n",
    "                batch_size * batch_idx,\n",
    "                batch_size * (batch_idx + 1)\n",
    "            ))\n",
    "            gold_labels = batch['ner_tags']\n",
    "            tokens = batch['tokens']\n",
    "            encoded_tokens = []\n",
    "            for token_seq in tokens:\n",
    "                encoded_seq = []\n",
    "                for token in token_seq:\n",
    "                    if token in tokens_to_idx:\n",
    "                        encoded_seq.append(tokens_to_idx[token])\n",
    "                    else:\n",
    "                        encoded_seq.append(tokens_to_idx[UNK])\n",
    "                encoded_tokens.append(torch.LongTensor(encoded_seq))\n",
    "            batch_predictions = decode_batch(model, encoded_tokens, idx_to_tags=idx_to_tags)\n",
    "            print('comp: ', gold_labels, batch_predictions)\n",
    "            break\n",
    "    # change when doing actual calcs\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6bc68e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_batch(model, batch, idx_to_tags:Dict[int, str]):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        padded_batch = pad_test_batch(batch)\n",
    "        x_padded, x_lens = padded_batch\n",
    "        result = model(x_padded, x_lens, None, decode=True)\n",
    "        actual_pred_tags = []\n",
    "        for pred, _ in result['tags']:\n",
    "            actual_pred_tags.append(pred)\n",
    "            # actual_pred_tags.append([idx_to_tags[i] for i in pred])\n",
    "    return actual_pred_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "83a07760",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset conll2003 (/Users/sabhyachhabria/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/40e7cb6bcc374f7c349c83acd1e9352a4f09474eb691f64f364ee62eb65d0ca6)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cfaae84dbdc4cefa0fac8b5aba7352d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train, val, test = load_data()\n",
    "ner_tags = train.features['ner_tags'].feature.names\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fdd3adbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_to_idx, idx_to_tokens = build_mappings(train['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "787d3206",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Conll2003(\n",
    "        examples=train['tokens'][:1000], labels=train['ner_tags'][:1000],\n",
    "        ner_tags=ner_tags, idx_to_tokens=idx_to_tokens, tokens_to_idx=tokens_to_idx,\n",
    "        device=device\n",
    "    )\n",
    "val_data = Conll2003(\n",
    "        examples=val['tokens'][:100], labels=val['ner_tags'][:100],\n",
    "        ner_tags=ner_tags, idx_to_tokens=idx_to_tokens, tokens_to_idx=tokens_to_idx,\n",
    "        device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a6407107",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=train_data, batch_size=16, shuffle=True, collate_fn=pad_batch)\n",
    "val_dataloader = DataLoader(dataset=val_data, batch_size=16, shuffle=True, collate_fn=pad_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "64c6095e",
   "metadata": {},
   "outputs": [],
   "source": [
    "crf_constraints = crf.allowed_transitions(\n",
    "        constraint_type='BIO',\n",
    "        labels=train_data.idx_to_tags\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fd36d3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTM_CRF(\n",
       "  (embeddings): Embedding(23624, 50)\n",
       "  (lstm): LSTM(50, 128, batch_first=True, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (linear): Linear(in_features=256, out_features=9, bias=True)\n",
       "  (crf): ConditionalRandomField()\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bilstm_crf = BiLSTM_CRF(\n",
    "        device=device,\n",
    "        vocab_size=len(idx_to_tokens.keys()),\n",
    "        num_tags=len(train_data.idx_to_tags.keys()),\n",
    "        embedding_dim=50,\n",
    "        lstm_hidden_dim=256,\n",
    "        lstm_num_layers=1,\n",
    "        dropout=0.2,\n",
    "        constraints=crf_constraints,\n",
    "        pad_idx=train_data.tokens_to_idx[PAD]\n",
    "    )\n",
    "bilstm_crf.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0fedd9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,367,932 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "num_params = count_parameters(bilstm_crf)\n",
    "print(f'The model has {num_params:,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6ec55d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(bilstm_crf.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5ead6da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 63/63 [00:03<00:00, 20.73batch/s]\n"
     ]
    }
   ],
   "source": [
    "train_loss = train_model(\n",
    "    model=bilstm_crf, dataloader=train_dataloader, optimizer=optimizer, clip=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d7ad9186",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 85.43batch/s]\n"
     ]
    }
   ],
   "source": [
    "val_loss = evaluate_model(model=bilstm_crf, dataloader=val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "240ffe05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp:  [[0, 0, 5, 0, 0, 0, 0, 1, 0, 0, 0, 0], [1, 2], [5, 0, 5, 6, 6, 0], [5, 0, 0, 0, 0, 0, 7, 8, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0]] [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [5, 1], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "test_f1 = test_eval(test_data=test, model=bilstm_crf, batch_size=4,\n",
    "                    idx_to_tokens=idx_to_tokens, tokens_to_idx=tokens_to_idx, idx_to_tags=train_data.idx_to_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b3cb90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c262c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
